# Interesting resources related to DataVis, ModelVis, InfoVis


## Papers

### 2018

*Journal of Imaging Science and Technology* Electronic Imaging, Visualization and Data Analysis 2018

* [RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records](https://arxiv.org/pdf/1805.10724.pdf); Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun, and Jaegul Choo;  Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a
particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no
established methods to interactively leverage users’ domain expertise and prior knowledge as inputs for steering the model. Therefore,
our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of
medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the
experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable,
and interactive RNN-based model called RetainEX and visualizations for users’ exploration of EMR data in the context of prediction
tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk
predictions, using EMRs of patients with heart failure and cataract symptoms.

* [Visual Exploration of Machine Learning Results using Data Cube Analysis](https://minsuk.com/research/papers/kahng-mlcube-hilda2016.pdf); Minsuk Kahng, Dezhi Fang, Duen Horng ; As complex machine learning systems become more widely adopted, it becomes increasingly challenging for users to understand models or interpret the results generated from the
models. We present our ongoing work on developing interactive and visual approaches for exploring and understanding
machine learning results using data cube analysis. We propose MLCube, a data cube inspired framework that enables
users to define instance subsets using feature conditions and computes aggregate statistics and evaluation metrics over
the subsets. We also design MLCube Explorer, an interactive visualization tool for comparing models’ performances
over the subsets. Users can interactively specify operations, such as drilling down to specific instance subsets, to perform
more in-depth exploration. 

* [RegressionExplorer: Interactive Exploration of Logistic Regression Models with Subgroup Analysis.](https://www.ncbi.nlm.nih.gov/pubmed/30222573); Dingen D, Veer MV, Houthuizen P, Mestrom EHJ, Korsten EHHM, Bouwman ARA, Wijk JV.
; Visual Analytics tool for the interactive exploration of logistic regression models. Our application domain is Clinical Biostatistics, where models are derived from patient data with the aim to obtain clinically meaningful insights and consequences. Development and interpretation of a proper model requires domain expertise and insight into model characteristics. Because of time constraints, often a limited number of candidate models is evaluated. RegressionExplorer enables experts to quickly generate, evaluate, and compare many different models, taking the workflow for model development as starting point. Global patterns in parameter values of candidate models can be explored effectively. In addition, experts are enabled to compare candidate models across multiple subpopulations. The insights obtained can be used to formulate new hypotheses or to steer model development. 


* [RuleMatrix: Visualizing and Understanding Classifiers with Rules](https://arxiv.org/pdf/1807.06228.pdf); Yao Ming, Huamin Qu, Enrico Bertini, M; With the growing adoption of machine learning techniques, there is a surge of research interest towards making machine
learning systems more transparent and interpretable. Various visualizations have been developed to help model developers understand,
diagnose, and refine machine learning models. However, a large number of potential but neglected users are the domain experts with
little knowledge of machine learning but are expected to work with machine learning systems. In this paper, we present an interactive
visualization technique to help users with little expertise in machine learning to understand, explore and validate predictive models.
By viewing the model as a black box, we extract a standardized rule-based knowledge representation from its input-output behavior.
We design RuleMatrix, a matrix-based visualization of rules to help users navigate and verify the rules and the black-box model. 

* [VIS4ML: An Ontology for Visual Analytics Assisted Machine Learning](https://bib.dbvis.de/uploadedFiles/TVCG2864838.pdf); Dominik Sacha, Matthias Kraus, Daniel A. Keim ; While many VA workflows make use of machine-learned models to support analytical tasks, VA workflows have become increasingly important in understanding and improving Machine Learning (ML) processes. In this paper, we propose an ontology (VIS4ML) for a subarea of VA, namely “VA-assisted ML”. The purpose of VIS4ML is to describe and understand existing VA workflows used in ML as well as to detect gaps in ML processes and the potential of introducing advanced VA techniques to such processes. Ontologies have been widely used to map out the scope of a topic in biology, medicine, and many other disciplines. We adopt the scholarly methodologies for constructing VIS4ML, including the specification, conceptualization, formalization, implementation, and validation of ontologies. In particular, we reinterpret the traditional VA pipeline to encompass model-development workflows. We introduce necessary definitions, rules, syntaxes, and visual notations for formulating VIS4ML and make use of semantic web technologies for implementing it in the Web Ontology Language (OWL). VIS4ML captures the high-level knowledge about previous workflows where VA is used to assist in ML. 

* [Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models](https://arxiv.org/abs/1804.09299); Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush; Neural Sequence-to-Sequence models have proven to be accurate and robust for many sequence prediction tasks, and have become the standard approach for automatic translation of text. The models work in a five stage blackbox process that involves encoding a source sequence to a vector space and then decoding out to a new target sequence. This process is now standard, but like many deep learning methods remains quite difficult to understand or debug. In this work, we present a visual analysis tool that allows interaction with a trained sequence-to-sequence model through each stage of the translation process. The aim is to identify which patterns have been learned and to detect model errors. We demonstrate the utility of our tool through several real-world large-scale sequence-to-sequence use cases.

* [Narvis: Authoring Narrative Slideshows for Introducing Data Visualization Designs](https://wangqianwen0418.github.io/assets/pdf/Narvis.pdf); Qianwen Wang, Zhen Li, Siwei Fu, Weiwei Cui, Huamin Qu; Visual designs can be complex in modern data visualization systems, which poses special challenges for explaining them to the non-experts. However, few if any presentation tools are tailored for this purpose. In this study, we present Narvis, a slideshow authoring tool designed for introducing data visualizations to non-experts. Narvis targets two types of end users: teachers, experts in data visualization who produce tutorials for explaining a data visualization, and students, non-experts who try to understand visualization designs through tutorials. We present an analysis of requirements through close discussions with the two types of end users. The resulting considerations guide the design and implementation of Narvis. Additionally, to help teachers better organize their introduction slideshows, we specify a data visualization as a hierarchical combination of components, which are automatically detected and extracted by Narvis. 

* [DimReader: Axis lines that explain non-linear projections](https://arxiv.org/abs/1710.00992); Rebecca Faust, David Glickenstein and Carlos Scheidegger; Non-linear dimensionality reduction (NDR) methods such as LLE and t-SNE are popular with visualization researchers and experienced data analysts, but present serious problems of interpretation. In this paper, we present DimReader, a technique that recovers readable axes from such techniques. DimReader is based on analyzing infinitesimal perturbations of the dataset with respect to variables of interest. The perturbations define exactly how we want to change each point in the original dataset and we measure the effect that these changes have on the projection. The recovered axes are in direct analogy with the axis lines (grid lines) of traditional scatterplots. We also present methods for discovering perturbations on the input data that change the projection the most. The calculation of the perturbations is efficient and easily integrated into programs written in modern programming languages. We present results of DimReader on a variety of NDR methods and datasets both synthetic and real-life, and show how it can be used to compare different NDR methods. 

* [EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection](https://arxiv.org/abs/1808.09074); Quan Li, Kristanto Sean Njotoprawiro, Hammad Haleem, Qiaoan Chen, Chris Yi, Xiaojuan Ma; Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. 

* [A Visual Technique to Analyze Flow of Information in a Machine Learning System](https://ist.publisher.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000001/art00013); Chaudhuri, Abon; Machine learning (ML) algorithms and machine learning based software systems implicitly or explicitly involve complex flow of information between various entities such as training data, feature space, validation set and results. Understanding the statistical distribution of such information and how they flow from one entity to another influence the operation and correctness of such systems, especially in large-scale applications that perform classification or prediction in real time. In this paper, we propose a visual approach to understand and analyze flow of information during model training and serving phases. We build the visualizations using a technique called Sankey Diagram - conventionally used to understand data flow among sets - to address various use cases of in a machine learning system. We demonstrate how the proposed technique, tweaked and twisted to suit a classification problem, can play a critical role in better understanding of the training data, the features, and the classifier performance. We also discuss how this technique enables diagnostic analysis of model predictions and comparative analysis of predictions from multiple classifiers. 

* [CNVis: A Web-Based Visual Analytics Tool for Exploring Conference Navigator Data](https://ist.publisher.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000001/art00009); Bailey, Samuel M.; Wei, Justin A.; Wang, Chaoli; Parra, Denis; Brusilovsky, Peter;  CNVis, a web-based visual analytics tool for exploring data from multiple related academic conferences, mainly consisting of the papers presented at the conferences and participants who bookmark these papers. Our goal is to investigate the bookmarking relationships within a single conference and interpret various conference relationships and trends via effective visualization, comparison, and recommendation. This 

* [A Step Towards Automatic Visual Analytics Pipeline Generation](https://ist.publisher.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000001/art00010); Karer, Benjamin; Scheler, Inga; Hagen, Hans; Automatic generation of data visualizations allows to quickly deploy data visualizations. In visual analytics, the combination of automatic and human analysis increases the effort necessary to achieve similar effects substantially. Where automatic visualization only needs to map the data, in visual analytics the whole data preparation and processing pipeline has to be considered. The user is interested in representations reflecting certain interpretations of the data, for example the idea that different groups represent different clusters in the data. In this paper, we prove that an information-driven automatic design of visual analytics pipelines is feasible. To this end, we prove that the ability of an analysis system to derive and visualize data supporting inquired information is decidable – at least for real-world applications. Having overcome this major obstacle, we outline a general algorithm scheme that can be implemented on a wide range of data and information models.

* [BGS: A Large-Scale Graph Visualization Tool](https://ist.publisher.ingentaconnect.com/contentone/ist/ei/2018/00002018/00000001/art00011); Zhang, Fangyan; Zhang, Song; Lightsey, Christopher; Harun, Sarah; Wong, Pak Chung; We present BGS (Big Graph Surfer), a scalable graph visualization tool that creates hierarchical structure from original graphs and provide interactive navigation along the hierarchy by expanding or collapsing clusters when visualizing large-scale graphs. A distributed computing framework-Spark provides the backend for BGS on clustering and visualization. This architecture makes it capable of visualizing a graph bigger than 1 billion nodes or edges in real-time after preprocessing.

IEEE VIS 

* [DQNViz: A Visual Analytics Approach to Understand Deep Q-Networks](http://edda-project.github.io/files/2018-08-13/dqnvis.pdf); Junpeng Wang, Liang Gou, Han-Wei Shen; Deep Q-Network (DQN), as one type of deep reinforcement learning model, targets to train an intelligent agent that acquires optimal actions while interacting with an environment. The model is well known for its ability to surpass professional human players across many Atari 2600 games. Despite the superhuman performance, in-depth understanding of the model and interpreting the sophisticated behaviors of the DQN agent remain to be challenging tasks, due to the long-time model training process and the large number of experiences dynamically generated by the agent. In this work, we propose DQNViz, a visual analytics system to expose details of the blind training process in four levels, and enable users to dive into the large experience space of the agent for comprehensive analysis.

* [iForest: Interpreting Random Forests via Visual Analytics](http://zhaoxun.me/publication/iForest.pdf); Xun Zhao, Yanhong Wu, Dik Lun Lee, and Weiwei Cui; As an ensemble model that consists of many independent decision trees, random forests generate predictions by feeding the input to internal trees and summarizing their outputs. The ensemble nature of the model helps random forests outperform any individual decision tree. However, it also leads to a poor model interpretability, which significantly hinders the model from being used in fields that require transparent and explainable predictions, such as medical diagnosis and financial fraud detection. T... To understand how a final prediction is achieved, it is desired to understand and compare all decision paths in the context of all tree structures, which is a huge challenge for any users. In this paper, we propose a visual analytic system aiming at interpreting random forest models and predictions. ... To demonstrate the effectiveness of our system, two usage scenarios and a qualitative user study are conducted.

* [Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models](https://arxiv.org/abs/1808.00196); Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, David S. Ebert; Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification).






* [DVQA: Understanding Data Visualizations via Question Answering](https://arxiv.org/pdf/1801.08163.pdf); Kushal Kafle, Brian Price, Scott Cohen, Christopher Kanan; Bar charts are an effective way to convey numeric information, but today’s algorithms cannot parse them. Existing methods fail when faced with even minor variations in appearance. Here, we present DVQA, a dataset that tests many aspects of bar chart understanding in a question answering framework. Unlike visual question answering (VQA), DVQA requires processing words and answers that are unique to a particular bar chart.

### 2012

* [Graphical Tests for Power Comparison of Competing Designs](https://ieeexplore.ieee.org/document/6327249); Heike Hofmann, Lendie Follett, Mahbubul Majumder, Dianne Cook; Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.

* [Validation of Visual Statistical Inference, with Application to Linear Models](https://pdfs.semanticscholar.org/eaef/fbc2760b36e6e27de237a64e6bff63bcce59.pdf); Mahbubul Majumder, Heike Hofmann, Dianne Cook; Statistical graphics play a crucial role in exploratory data analysis, model checking and diagnosis. Until recently there were no formal visual methods in place for determining statistical significance of findings. This changed, when Buja et al. (2009) conceptually introduced two protocols for formal tests of visual findings. In this paper we take this a step  urther by comparing the lineup protocol (Buja et al., 2009) against classical statistical testing of the significance of regression model parameters. A human subjects experiment is conducted using simulated data to provide controlled conditions. Results suggest that the lineup protocol provides results equivalent to the uniformly most powerful (UMP) test and for some scenarios yields better power than the UMP test.




### 2010

* [Graphical Inference for Infovis](http://jonathanstray.com/papers/wickham.pdf); Hadley Wickham, Dianne Cook, Heike Hofmann, and Andreas Buja; How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The “Rorschach” helps the analyst calibrate their understanding of uncertainty and the "lineup" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.


## Talks

### 2018

* [Human vs computer: when visualising data, who wins?](https://www.dicook.org/files/belz-cook/#1); Di Cook; Statistical inference with graphics, follows classical hypothesis testing procedures; Lineup protocol embeds the data plot among a field of null plots (comparison of test statistic with sampling distribution); Human observers pick plot that is most different from the others; P-value calculated from the probability that the data plot is selected by chance



## Books



## Tools

### 2018

* [DRX-VIS](https://sites.google.com/view/dxr-vis); DXR is a toolkit for rapidly prototyping Data visualizations in XR (augmented, mixed, and virtual reality). A visualization in DXR is a collection of Unity game objects whose properties  such as position, color, and size are mapped to data attributes. This mapping can be specified interactively at runtime via a graphical user interface (GUI) or via a high-level programming interface, inspired by Polestar and Vega-Lite, respectively. DXR is extensible, allowing the use of most Unity game objects for custom marks and channels. To learn more, check out the top navigation bar or the following links:
